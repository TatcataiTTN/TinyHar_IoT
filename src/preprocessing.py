#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Preprocessing Pipeline cho HAR
Chuáº©n hÃ³a vÃ  reshape dá»¯ liá»‡u cho model
"""

import numpy as np
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split
import pickle
import os

def preprocess_data(X_train, X_test, y_train, y_test, 
                   scaler_type='standard', validation_split=0.2,
                   save_scaler=True, scaler_path='models/scaler.pkl'):
    """
    Chuáº©n hÃ³a vÃ  chia dá»¯ liá»‡u
    
    Args:
        X_train, X_test: Dá»¯ liá»‡u features
        y_train, y_test: Labels
        scaler_type: 'standard' hoáº·c 'minmax'
        validation_split: Tá»· lá»‡ validation (0.2 = 20%)
        save_scaler: LÆ°u scaler Ä‘á»ƒ dÃ¹ng sau
        scaler_path: ÄÆ°á»ng dáº«n lÆ°u scaler
        
    Returns:
        X_train, X_val, X_test, y_train, y_val, y_test, scaler
    """
    print("=" * 60)
    print("Preprocessing dá»¯ liá»‡u...")
    print("=" * 60)
    
    # Chá»n scaler
    if scaler_type == 'standard':
        scaler = StandardScaler()
        print("ğŸ“Š Sá»­ dá»¥ng StandardScaler (mean=0, std=1)")
    else:
        scaler = MinMaxScaler()
        print("ğŸ“Š Sá»­ dá»¥ng MinMaxScaler (range 0-1)")
    
    # Fit scaler trÃªn training data
    print("\nğŸ”§ Äang fit scaler trÃªn training data...")
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    print(f"âœ… X_train scaled: min={X_train_scaled.min():.4f}, max={X_train_scaled.max():.4f}")
    print(f"âœ… X_test scaled: min={X_test_scaled.min():.4f}, max={X_test_scaled.max():.4f}")
    
    # Chia validation set tá»« training data
    print(f"\nğŸ“‚ Chia validation set ({validation_split*100:.0f}%)...")
    X_train_final, X_val, y_train_final, y_val = train_test_split(
        X_train_scaled, y_train, 
        test_size=validation_split, 
        random_state=42,
        stratify=y_train  # Äáº£m báº£o tá»· lá»‡ classes Ä‘á»u
    )
    
    print(f"âœ… Training set: {X_train_final.shape[0]} samples")
    print(f"âœ… Validation set: {X_val.shape[0]} samples")
    print(f"âœ… Test set: {X_test_scaled.shape[0]} samples")
    
    # Kiá»ƒm tra phÃ¢n bá»‘ classes
    print("\nğŸ“Š PhÃ¢n bá»‘ classes:")
    for i in range(int(y_train.max()) + 1):
        train_count = np.sum(y_train_final == i)
        val_count = np.sum(y_val == i)
        test_count = np.sum(y_test == i)
        print(f"  Class {i}: Train={train_count:4d}, Val={val_count:4d}, Test={test_count:4d}")
    
    # LÆ°u scaler
    if save_scaler:
        os.makedirs(os.path.dirname(scaler_path), exist_ok=True)
        with open(scaler_path, 'wb') as f:
            pickle.dump(scaler, f)
        print(f"\nğŸ’¾ ÄÃ£ lÆ°u scaler táº¡i: {scaler_path}")
    
    print("\n" + "=" * 60)
    print("âœ… Preprocessing hoÃ n táº¥t!")
    print("=" * 60)
    
    return X_train_final, X_val, X_test_scaled, y_train_final, y_val, y_test, scaler


def reshape_for_cnn(X_train, X_val, X_test, window_size=128, n_channels=9):
    """
    Reshape dá»¯ liá»‡u cho CNN input
    UCI HAR cÃ³ 561 features, ta sáº½ reshape thÃ nh (samples, timesteps, features)
    
    Args:
        X_train, X_val, X_test: Dá»¯ liá»‡u Ä‘Ã£ scaled
        window_size: Sá»‘ timesteps (máº·c Ä‘á»‹nh 128)
        n_channels: Sá»‘ channels (máº·c Ä‘á»‹nh 9 cho IMU)
        
    Returns:
        X_train, X_val, X_test Ä‘Ã£ reshape
    """
    print("\nğŸ”„ Reshape dá»¯ liá»‡u cho CNN...")
    
    # UCI HAR cÃ³ 561 features, ta giá»¯ nguyÃªn shape (samples, 561, 1)
    # Hoáº·c cÃ³ thá»ƒ reshape thÃ nh (samples, 128, 9) náº¿u cáº§n
    X_train_reshaped = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
    X_val_reshaped = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)
    X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)
    
    print(f"âœ… X_train shape: {X_train_reshaped.shape}")
    print(f"âœ… X_val shape: {X_val_reshaped.shape}")
    print(f"âœ… X_test shape: {X_test_reshaped.shape}")
    
    return X_train_reshaped, X_val_reshaped, X_test_reshaped


def load_scaler(scaler_path='models/scaler.pkl'):
    """
    Load scaler Ä‘Ã£ lÆ°u
    
    Args:
        scaler_path: ÄÆ°á»ng dáº«n file scaler
        
    Returns:
        scaler object
    """
    with open(scaler_path, 'rb') as f:
        scaler = pickle.load(f)
    print(f"âœ… ÄÃ£ load scaler tá»«: {scaler_path}")
    return scaler


if __name__ == '__main__':
    # Test preprocessing
    print("\nğŸ§ª Testing Preprocessing Pipeline...\n")
    
    # Import data loader
    from data_loader import load_uci_har_data
    
    # Load data
    X_train, X_test, y_train, y_test, _, _, _ = load_uci_har_data()
    
    # Preprocess
    X_train_p, X_val_p, X_test_p, y_train_p, y_val_p, y_test_p, scaler = preprocess_data(
        X_train, X_test, y_train, y_test,
        scaler_type='standard',
        validation_split=0.2
    )
    
    # Reshape cho CNN
    X_train_r, X_val_r, X_test_r = reshape_for_cnn(X_train_p, X_val_p, X_test_p)
    
    print("\nâœ… Preprocessing pipeline hoáº¡t Ä‘á»™ng tá»‘t!")

