#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Data Loader cho UCI HAR Dataset
Táº£i vÃ  parse dá»¯ liá»‡u tá»« UCI HAR Dataset
"""

import numpy as np
import os
import sys

def load_uci_har_data(dataset_path='datasets/UCI HAR Dataset'):
    """
    Táº£i UCI HAR Dataset
    
    Args:
        dataset_path: ÄÆ°á»ng dáº«n Ä‘áº¿n thÆ° má»¥c dataset
        
    Returns:
        X_train, X_test, y_train, y_test, subject_train, subject_test
    """
    print("=" * 60)
    print("Äang táº£i UCI HAR Dataset...")
    print("=" * 60)
    
    # Kiá»ƒm tra dataset cÃ³ tá»“n táº¡i khÃ´ng
    if not os.path.exists(dataset_path):
        print(f"âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y dataset táº¡i {dataset_path}")
        print("HÃ£y cháº¡y: python scripts/download_dataset.py")
        sys.exit(1)
    
    # ÄÆ°á»ng dáº«n cÃ¡c file
    train_path = os.path.join(dataset_path, 'train')
    test_path = os.path.join(dataset_path, 'test')
    
    # Load training data
    print("\nğŸ“‚ Äang táº£i training data...")
    X_train = np.loadtxt(os.path.join(train_path, 'X_train.txt'))
    y_train = np.loadtxt(os.path.join(train_path, 'y_train.txt'))
    subject_train = np.loadtxt(os.path.join(train_path, 'subject_train.txt'))
    
    print(f"âœ… X_train: {X_train.shape}")
    print(f"âœ… y_train: {y_train.shape}")
    print(f"âœ… subject_train: {subject_train.shape}")
    
    # Load test data
    print("\nğŸ“‚ Äang táº£i test data...")
    X_test = np.loadtxt(os.path.join(test_path, 'X_test.txt'))
    y_test = np.loadtxt(os.path.join(test_path, 'y_test.txt'))
    subject_test = np.loadtxt(os.path.join(test_path, 'subject_test.txt'))
    
    print(f"âœ… X_test: {X_test.shape}")
    print(f"âœ… y_test: {y_test.shape}")
    print(f"âœ… subject_test: {subject_test.shape}")
    
    # Load activity labels
    activity_labels = {}
    with open(os.path.join(dataset_path, 'activity_labels.txt'), 'r') as f:
        for line in f:
            idx, label = line.strip().split()
            activity_labels[int(idx)] = label
    
    print("\nğŸ“‹ CÃ¡c hoáº¡t Ä‘á»™ng:")
    for idx, label in activity_labels.items():
        count_train = np.sum(y_train == idx)
        count_test = np.sum(y_test == idx)
        print(f"  {idx}. {label:20s} - Train: {count_train:4d}, Test: {count_test:4d}")
    
    # Chuyá»ƒn labels vá» 0-indexed (tá»« 1-6 thÃ nh 0-5)
    y_train = y_train - 1
    y_test = y_test - 1
    
    print("\n" + "=" * 60)
    print("âœ… Táº£i dá»¯ liá»‡u thÃ nh cÃ´ng!")
    print("=" * 60)
    
    return X_train, X_test, y_train, y_test, subject_train, subject_test, activity_labels


def get_dataset_info(dataset_path='datasets/UCI HAR Dataset'):
    """
    Láº¥y thÃ´ng tin vá» dataset
    
    Args:
        dataset_path: ÄÆ°á»ng dáº«n Ä‘áº¿n thÆ° má»¥c dataset
        
    Returns:
        dict chá»©a thÃ´ng tin dataset
    """
    info = {
        'num_features': 561,
        'num_classes': 6,
        'sampling_rate': 50,  # Hz
        'window_size': 2.56,  # seconds
        'overlap': 0.5,  # 50%
    }
    
    return info


if __name__ == '__main__':
    # Test data loader
    print("\nğŸ§ª Testing Data Loader...\n")
    
    X_train, X_test, y_train, y_test, subject_train, subject_test, labels = load_uci_har_data()
    
    print("\nğŸ“Š Thá»‘ng kÃª dá»¯ liá»‡u:")
    print(f"  - Sá»‘ features: {X_train.shape[1]}")
    print(f"  - Sá»‘ classes: {len(np.unique(y_train))}")
    print(f"  - Training samples: {X_train.shape[0]}")
    print(f"  - Test samples: {X_test.shape[0]}")
    print(f"  - Sá»‘ ngÆ°á»i tham gia train: {len(np.unique(subject_train))}")
    print(f"  - Sá»‘ ngÆ°á»i tham gia test: {len(np.unique(subject_test))}")
    
    # Kiá»ƒm tra giÃ¡ trá»‹
    print("\nğŸ” Kiá»ƒm tra dá»¯ liá»‡u:")
    print(f"  - X_train min: {X_train.min():.4f}, max: {X_train.max():.4f}")
    print(f"  - X_test min: {X_test.min():.4f}, max: {X_test.max():.4f}")
    print(f"  - y_train unique: {np.unique(y_train)}")
    print(f"  - y_test unique: {np.unique(y_test)}")
    
    print("\nâœ… Data loader hoáº¡t Ä‘á»™ng tá»‘t!")

