#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script chuy·ªÉn ƒë·ªïi models sang TensorFlow Lite v√† C arrays cho ESP32
T·∫•t c·∫£ comments b·∫±ng ti·∫øng Vi·ªát
"""

import os
import json
import numpy as np
import tensorflow as tf
from tensorflow import keras

def convert_to_tflite(model_path, output_path, quantize=True, model_type='cnn'):
    """
    Chuy·ªÉn ƒë·ªïi model Keras sang TensorFlow Lite

    Args:
        model_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file .h5
        output_path: ƒê∆∞·ªùng d·∫´n output file .tflite
        quantize: C√≥ √°p d·ª•ng quantization kh√¥ng (int8)
        model_type: Lo·∫°i model ('cnn', 'lstm', 'cnn_lstm')

    Returns:
        K√≠ch th∆∞·ªõc file .tflite (bytes)
    """
    # Load model
    model = keras.models.load_model(model_path)

    # T·∫°o converter
    converter = tf.lite.TFLiteConverter.from_keras_model(model)

    if quantize:
        # √Åp d·ª•ng quantization int8 (ch·ªâ weights, kh√¥ng quantize input/output)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]

        # Representative dataset ƒë·ªÉ calibrate quantization
        def representative_dataset():
            # Load d·ªØ li·ªáu m·∫´u ƒë·ªÉ calibrate
            # Shape ph·∫£i kh·ªõp v·ªõi input c·ªßa model: (1, 561, 1)
            for _ in range(100):
                data = np.random.randn(1, 561, 1).astype(np.float32)
                yield [data]

        converter.representative_dataset = representative_dataset

        # ƒê·ªëi v·ªõi LSTM models, c·∫ßn th√™m SELECT_TF_OPS
        if 'lstm' in model_type.lower():
            converter.target_spec.supported_ops = [
                tf.lite.OpsSet.TFLITE_BUILTINS,
                tf.lite.OpsSet.SELECT_TF_OPS
            ]
            converter._experimental_lower_tensor_list_ops = False
        else:
            converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]

    # Convert
    tflite_model = converter.convert()

    # L∆∞u file
    with open(output_path, 'wb') as f:
        f.write(tflite_model)

    return len(tflite_model)

def convert_to_c_array(tflite_path, output_path, model_name):
    """
    Chuy·ªÉn ƒë·ªïi file .tflite sang C header file
    
    Args:
        tflite_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file .tflite
        output_path: ƒê∆∞·ªùng d·∫´n output file .h
        model_name: T√™n model (d√πng cho t√™n bi·∫øn trong C)
    """
    # ƒê·ªçc file .tflite
    with open(tflite_path, 'rb') as f:
        tflite_data = f.read()
    
    # T·∫°o C array
    hex_array = ', '.join([f'0x{b:02x}' for b in tflite_data])
    
    # T·∫°o n·ªôi dung file .h
    c_code = f"""// Auto-generated C header file cho model: {model_name}
// K√≠ch th∆∞·ªõc: {len(tflite_data)} bytes
// Ng√†y t·∫°o: 2026-01-14

#ifndef {model_name.upper()}_MODEL_H
#define {model_name.upper()}_MODEL_H

// K√≠ch th∆∞·ªõc model (bytes)
const unsigned int {model_name}_model_len = {len(tflite_data)};

// Model data (TensorFlow Lite format)
const unsigned char {model_name}_model[] = {{
  {hex_array}
}};

#endif  // {model_name.upper()}_MODEL_H
"""
    
    # L∆∞u file
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(c_code)
    
    return len(tflite_data)

def process_all_models():
    """X·ª≠ l√Ω t·∫•t c·∫£ 6 models"""
    
    # T·∫°o th∆∞ m·ª•c output
    os.makedirs('models/tflite', exist_ok=True)
    os.makedirs('models/c_arrays', exist_ok=True)
    
    # Danh s√°ch models
    models = {
        'cnn_simple': 'CNN ƒê∆°n Gi·∫£n',
        'cnn_deep': 'CNN S√¢u',
        'lstm': 'LSTM',
        'cnn_lstm': 'CNN-LSTM',
        'depthwise_cnn': 'Depthwise CNN',
        'cnn_attention': 'CNN Attention'
    }
    
    results = {}
    
    print("=" * 80)
    print("üîÑ CHUY·ªÇN ƒê·ªîI MODELS SANG TENSORFLOW LITE V√Ä C ARRAYS")
    print("=" * 80)
    
    for i, (model_key, model_name) in enumerate(models.items(), 1):
        print(f"\nüì¶ [{i}/6] X·ª≠ l√Ω: {model_name} ({model_key})")
        print("-" * 80)
        
        model_path = f'models/har_model_{model_key}.h5'
        
        if not os.path.exists(model_path):
            print(f"   ‚ö†Ô∏è  File kh√¥ng t·ªìn t·∫°i: {model_path}")
            continue
        
        try:
            # L·∫•y k√≠ch th∆∞·ªõc g·ªëc
            original_size = os.path.getsize(model_path)
            
            # Chuy·ªÉn sang TFLite (float32)
            tflite_float_path = f'models/tflite/{model_key}_float32.tflite'
            print(f"   üîÑ Chuy·ªÉn sang TFLite (float32)...")
            tflite_float_size = convert_to_tflite(model_path, tflite_float_path, quantize=False, model_type=model_key)

            # Chuy·ªÉn sang TFLite (int8 quantized)
            tflite_int8_path = f'models/tflite/{model_key}_int8.tflite'
            print(f"   üîÑ Chuy·ªÉn sang TFLite (int8 quantized)...")
            tflite_int8_size = convert_to_tflite(model_path, tflite_int8_path, quantize=True, model_type=model_key)
            
            # Chuy·ªÉn sang C array (int8)
            c_array_path = f'models/c_arrays/{model_key}_model.h'
            print(f"   üîÑ Chuy·ªÉn sang C header file...")
            c_array_size = convert_to_c_array(tflite_int8_path, c_array_path, model_key)
            
            # T√≠nh t·ª∑ l·ªá gi·∫£m
            reduction_float = (1 - tflite_float_size / original_size) * 100
            reduction_int8 = (1 - tflite_int8_size / original_size) * 100
            
            # L∆∞u k·∫øt qu·∫£
            results[model_key] = {
                'name': model_name,
                'original_size_bytes': original_size,
                'original_size_kb': original_size / 1024,
                'tflite_float32_size_bytes': tflite_float_size,
                'tflite_float32_size_kb': tflite_float_size / 1024,
                'tflite_int8_size_bytes': tflite_int8_size,
                'tflite_int8_size_kb': tflite_int8_size / 1024,
                'reduction_float32_percent': reduction_float,
                'reduction_int8_percent': reduction_int8
            }
            
            print(f"   ‚úÖ Ho√†n t·∫•t!")
            print(f"      ‚Ä¢ G·ªëc (.h5):          {original_size:,} bytes ({original_size/1024:.2f} KB)")
            print(f"      ‚Ä¢ TFLite (float32):   {tflite_float_size:,} bytes ({tflite_float_size/1024:.2f} KB) - Gi·∫£m {reduction_float:.1f}%")
            print(f"      ‚Ä¢ TFLite (int8):      {tflite_int8_size:,} bytes ({tflite_int8_size/1024:.2f} KB) - Gi·∫£m {reduction_int8:.1f}%")
            
        except Exception as e:
            print(f"   ‚ùå L·ªói: {e}")
            import traceback
            traceback.print_exc()
    
    # L∆∞u k·∫øt qu·∫£ v√†o JSON
    results_path = 'models/conversion_results.json'
    with open(results_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print("\n" + "=" * 80)
    print("‚úÖ HO√ÄN T·∫§T CHUY·ªÇN ƒê·ªîI T·∫§T C·∫¢ MODELS")
    print("=" * 80)
    print(f"\nüìÑ K·∫øt qu·∫£ ƒë√£ l∆∞u v√†o: {results_path}")
    
    return results

if __name__ == '__main__':
    results = process_all_models()

